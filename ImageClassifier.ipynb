{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe86951",
   "metadata": {},
   "source": [
    "# Reading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18674924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataPath = r\"C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\menotme.csv\"\n",
    "data = pd.read_csv(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "866a4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac = 1)\n",
    "data[\"Label\"] = data[\"Label\"].astype('category')\n",
    "data[\"Label\"] = data[\"Label\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "742c4a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_1369.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\DMJX7482.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\18_1_0_20170109214557098.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_5680.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_4865.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\21_0_4_20161223214830361.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\PMOY3226.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\21_1_3_20170104222105822.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_5721.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_7153.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_0452.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\DLOF5000.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\21_0_4_20170103223143358.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\16_1_0_20170109213504335.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\10_0_0_20161220222308131.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\15_0_0_20170116201123807.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\CODSE7163.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_E4507.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\33_0_0_20170117145924419.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_4544.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\16_0_0_20170110225715009.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_2932.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_5507.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\4_1_4_20170103210522819.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_3113.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\LVOL2173.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_3311.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\21_0_4_20161223214805057.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_3257.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\18_1_3_20170119153619553.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\24_0_2_20170104020029454.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IYKW1813.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\29_1_2_20170104023153742.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_5374.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\LWLN1248.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\XZCME3060.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\18_0_1_20170113132629362.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\16_1_0_20170109214138699.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\29_0_3_20170119195500659.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\16_0_0_20170110231532894.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_3075.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_0481.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_6577.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_3301.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\HXWM8039.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\24_0_2_20170103223924087.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_6295.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\BPLA9963.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\20_1_4_20161223230050564.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_4390.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_6239.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\GOHI6895.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\32_1_1_20170112203815123.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\5da7d5a6-735e-4d4c-b6c3-7d1a5723b45f.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_2683.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_2615.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\KBGV1024.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\14_1_0_20170103200702463.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_1548.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\21_0_4_20170114030756751.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\16_0_0_20170110231736665.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\16_0_0_20170110231521377.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_4403.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_0458.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\HXAV2394.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\15_0_2_20170116181405111.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_2617.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_7474.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_5722.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\31_0_0_20170109003033356.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\SBSUE1675.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\29_0_4_20170117202710430.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_3986.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\8ec642d7-6a76-40e6-8eca-ea1bde5a1fb3.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_5809.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_E3911.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\HVDU7098.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\18_1_3_20170104221918414.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_1872.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\30_1_4_20170117203559144.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_E4789.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\13_1_0_20170110224453650.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_5538.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\QNRXE6698.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_3242.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_5720.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_3703.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\GNXDE8515.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_0457.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_6762.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\TGRJ9855.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_0450.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\_MG_0305.jpeg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_E7468.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\ANGS4735.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\22_1_3_20170104232504850.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\QCZN3165.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\JXYA5730.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\18_1_0_20170109214120554.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_5581.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\NNEI5653.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_6987.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_E4506.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\18_1_3_20170104221905278.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_5398.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_2479.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_9826.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\16_1_0_20170109213440225.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_2820.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_6572.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\31_0_0_20170105164926876.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\22_1_3_20170104232021658.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_6822.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\26_1_0_20170117173648397.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\SFPO8457.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\20_1_3_20170119153755113.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\E926C9E2-CA03-4724-B05D-5DA4324A36C1.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\34_1_3_20170119155627753.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_2930.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_3841.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_5529.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\15_1_0_20170109214723528.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_0451.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\22_0_0_20170119150313790.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\_MG_0473.jpeg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\12_1_3_20161220222343139.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\RLKI7415.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\ACHH6285.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\15_1_0_20170109214523308.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_2929.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\18_1_3_20170104214217685.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_5281.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\29_1_2_20170116163011756.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_3544.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_7565.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_2931.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\79421387-E978-4BC6-868E-CACB13AAA948.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_7568.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_1592.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\VIAX3875.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\DQXOE2112.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\TBIW7848.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_5365.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\dd52610e-dccc-4fb3-a665-8fa626aab9a3.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_6876.JPEG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\14_1_0_20170103201434935.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\20_1_3_20170104233643891.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\16_1_0_20170109213456322.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\21_0_4_20161223214759249.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\images of not me\\34_1_4_20170103182156641.jpg.chip.jpg\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\IMG_2988.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\maryam\\BXRH3047.JPG\n",
      "C:\\Users\\HF\\Desktop\\Fall 2023\\deep learning\\iCloud Photos from Shaheen Amir\\IMG_2819.JPEG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "resized=[]\n",
    "\n",
    "for i in data[\"Path\"]:\n",
    "    image = cv2.imread(i,cv2.IMREAD_UNCHANGED)\n",
    "    resize=cv2.resize(image,(220,220))#can resize however you want\n",
    "    r = np.array(resize)\n",
    "    resized.append(r)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc088ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "317ef71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized=np.array(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42ffeefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153, 220, 220, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d00f3e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot_encoded = label_binarizer.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f17f0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(resized, y_one_hot_encoded, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4d4108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('train_test_splits.pkl', 'wb') as file:\n",
    "    pickle.dump((X_train, X_test, y_train, y_test), file)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "aeb7d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loading\n",
    "import pickle\n",
    "with open('train_test_splits.pkl', 'rb') as file:\n",
    "    X_train1, X_test1, y_train1, y_test1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "655ac70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1=X_train1/255\n",
    "X_test1=X_test1/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2efb4c",
   "metadata": {},
   "source": [
    "# Using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "99217254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 220, 220, 3)]     0         \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 145200)            0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 128)               18585728  \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18594179 (70.93 MB)\n",
      "Trainable params: 18594179 (70.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "image_height, image_width, num_channels = 220, 220, 3 \n",
    "\n",
    "num_classes = 3 \n",
    "\n",
    "input_shape = (image_height, image_width, num_channels)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = Flatten()(inputs)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "cf668cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 441ms/step - loss: 65.9939 - accuracy: 0.3402 - val_loss: 32.6545 - val_accuracy: 0.3200\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 31.4542 - accuracy: 0.3505 - val_loss: 15.3403 - val_accuracy: 0.2400\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 13.5936 - accuracy: 0.4742 - val_loss: 12.6526 - val_accuracy: 0.3600\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 5.2463 - accuracy: 0.5773 - val_loss: 10.1747 - val_accuracy: 0.6400\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 14.2760 - accuracy: 0.5567 - val_loss: 3.2099 - val_accuracy: 0.3600\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 6.6382 - accuracy: 0.5876 - val_loss: 25.0891 - val_accuracy: 0.3600\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 14.8786 - accuracy: 0.5155 - val_loss: 3.4133 - val_accuracy: 0.3600\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 5.1919 - accuracy: 0.6082 - val_loss: 6.5148 - val_accuracy: 0.5600\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 6.2275 - accuracy: 0.5979 - val_loss: 1.7108 - val_accuracy: 0.4800\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.9380 - accuracy: 0.8041 - val_loss: 1.8435 - val_accuracy: 0.5200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25a469c9450>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train1, y_train1, epochs=10, batch_size=32,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3c598478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "eb853432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predicted_labels = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "de5f7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(np.argmax(y_test1, axis=1), predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2eb6d350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7419354838709677"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa795685",
   "metadata": {},
   "source": [
    "# Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "be11921f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 220, 220, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 218, 218, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPooli  (None, 109, 109, 32)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 107, 107, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPooli  (None, 53, 53, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 51, 51, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPooli  (None, 25, 25, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 80000)             0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 128)               10240128  \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10341827 (39.45 MB)\n",
      "Trainable params: 10341827 (39.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(num_classes, activation='softmax')(x) \n",
    "\n",
    "model1 = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'model_checkpoint.h5', monitor='', save_best_only=True, mode='min')\n",
    "checkpoint_callback2=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=2,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0,\n",
    ")\n",
    "model1.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "def30535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7864 - accuracy: 0.3093WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 9s 2s/step - loss: 1.7864 - accuracy: 0.3093 - val_loss: 1.0727 - val_accuracy: 0.3200\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0520 - accuracy: 0.3402WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 2s/step - loss: 1.0520 - accuracy: 0.3402 - val_loss: 1.0356 - val_accuracy: 0.7200\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9929 - accuracy: 0.7629WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 2s/step - loss: 0.9929 - accuracy: 0.7629 - val_loss: 1.1136 - val_accuracy: 0.4400\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0123 - accuracy: 0.5155WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 2s/step - loss: 1.0123 - accuracy: 0.5155 - val_loss: 0.7626 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6237 - accuracy: 0.8454WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 2s/step - loss: 0.6237 - accuracy: 0.8454 - val_loss: 0.5588 - val_accuracy: 0.7600\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4795 - accuracy: 0.7732WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 9s 2s/step - loss: 0.4795 - accuracy: 0.7732 - val_loss: 0.4884 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3522 - accuracy: 0.8454WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 9s 2s/step - loss: 0.3522 - accuracy: 0.8454 - val_loss: 0.9968 - val_accuracy: 0.6400\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8368 - accuracy: 0.7216WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with  available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 2s/step - loss: 0.8368 - accuracy: 0.7216 - val_loss: 1.1636 - val_accuracy: 0.5200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25a60a609d0>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train1, y_train1, epochs=20, batch_size=32, validation_split=0.2,callbacks=[checkpoint_callback,checkpoint_callback2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f037002f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 502ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction2=model1.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "dcfa9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels2 = np.argmax(prediction2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4079baa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy2= accuracy_score(np.argmax(y_test1, axis=1), predicted_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e7e77202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8064516129032258"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
